# ğŸ“š AI Exam Answer Evaluator & Feedback Generator

An AI-powered system that evaluates student exam answer sheets and generates feedback automatically using OCR + LLM.

This project is designed to help teachers reduce manual correction time by extracting questions and answers from PDFs (typed or handwritten), assigning marks, generating feedback, and exporting results.

---

## ğŸš€ Features

âœ… Upload Teacher Question Paper PDF  
âœ… Upload Student Answer Sheet PDF  
âœ… Extract questions using OCR (EasyOCR)  
âœ… Extract student answers from PDF  
âœ… AI-based evaluation using Groq LLM  
âœ… Marks and grade calculation  
âœ… Feedback generation (Strengths + Improvements)  
âœ… Export evaluation report as CSV  
âœ… Streamlit based professional dashboard UI  

---

## ğŸ› ï¸ Technologies Used

- **Python**
- **Streamlit**
- **EasyOCR**
- **PyMuPDF (fitz)**
- **Groq API**
- **Pandas**
- **JSON**
- **PDF Processing**

---
## ğŸ“‚ Project Structure

AI-Exam-Answer-Evaluator-Feedback-Generator/
â”‚
â”œâ”€â”€ gen_ai_project.ipynb # Main Colab notebook
â”œâ”€â”€ app.py # Streamlit application (if added)
â”œâ”€â”€ requirements.txt # Dependencies (if added)
â””â”€â”€ README.md # Project documentation


---

## âš™ï¸ How It Works

1. Teacher uploads **Question Paper PDF**
2. Student uploads **Answer Sheet PDF**
3. OCR extracts text from both PDFs
4. System matches questions and answers
5. Groq LLM evaluates answers based on the question
6. Marks, feedback and grade are generated
7. Final results exported as CSV report

---

## ğŸ“Œ Installation & Setup (Local)

### Step 1: Clone Repository
```bash
git clone https://github.com/Kaviyadharshini23/AI-Exam-Answer-Evaluator-Feedback-Generator.git
cd AI-Exam-Answer-Evaluator-Feedback-Generator
ğŸ“Š Output

The system generates:

Extracted questions & answers

Marks per question

Total score

Grade

AI feedback

CSV report export

ğŸ¯ Use Cases

ğŸ“Œ Schools and colleges
ğŸ“Œ Online exam platforms
ğŸ“Œ Teachers and training institutes
ğŸ“Œ AI-based assessment tools
